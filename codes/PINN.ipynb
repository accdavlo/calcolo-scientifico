{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/accdavlo/calcolo-scientifico/blob/main/codes/PINN.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Physics Informed Neural Network (PINN)\n",
        "Questo notebook è stato sviluppato da Francesco Morrocco durante il suo progetto di tesi triennale.\n",
        "\n",
        "Vedremo l'implementazione di PINN per problemi ellittici, iperbolici e parabolici e li confronteremo con metodi numerici standard (elementi finiti, differenze finite).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyJeQlGp4HEA"
      },
      "source": [
        "# Dipendenze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j76sNwUHIaK_"
      },
      "outputs": [],
      "source": [
        "# Installing FEniCS (dolfin) on the Google Colab servers\n",
        "try:\n",
        "    import dolfin\n",
        "except ImportError:\n",
        "    !wget \"https://fem-on-colab.github.io/releases/fenics-install-release-real.sh\" -O \"/tmp/fenics-install.sh\" && bash \"/tmp/fenics-install.sh\"\n",
        "    import dolfin\n",
        "from dolfin import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3CH6Tf2I5Iz"
      },
      "outputs": [],
      "source": [
        "# Importing some libraries\n",
        "from dolfin import * # This is the core of FEniCS and it contains all the FEM functions we will need\n",
        "from ufl_legacy.geometry import * # This helps in designing geometries\n",
        "from dolfin.cpp.mesh import *     # This handles meshes\n",
        "from mshr import *                # This generates meshes\n",
        "from mshr import Circle, generate_mesh\n",
        "import matplotlib.tri as tri\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spla\n",
        "\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMl9LDbn4Lay"
      },
      "source": [
        "# Rete Neurale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HOFKvRS2KT8"
      },
      "source": [
        "Una rete neurale artificiale è un modello parametrico che definisce una funzione\n",
        "$$\n",
        "  F \\colon \\mathbb{R}^n \\longrightarrow \\mathbb{R}^m\n",
        "$$\n",
        "ottenuta mediante la composizione di più trasformazioni elementari. Ogni trasformazione è composta da uno strato di neuroni artificiali, ciascuno dei quali calcola prima una combinazione lineare degli ingressi\n",
        "$$\n",
        "  f = W x + \\beta\n",
        "$$\n",
        "dove $W\\in\\mathbb{R}^{k \\times k-1}$ è il vettore di parametri o pesi e $b\\in\\mathbb{R}^{k}$ il bias e $x\\in \\mathbb{R}^{k-1}$ è il vettore in input; poi si applica una funzione di attivazione $\\sigma(f)$ per introdurre non linearità. In questo caso è stata usata la $\\tanh(x)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUKj64VycmlC"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, layers=[2,50,50,50,1]):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = nn.Sequential()\n",
        "        for i in range(len(layers) - 2):\n",
        "            self.net.add_module(f\"layer_{i}\", nn.Linear(layers[i], layers[i+1]))\n",
        "            self.net.add_module(f\"tanh_{i}\", nn.Tanh())\n",
        "        self.net.add_module(\"output\", nn.Linear(layers[-2], layers[-1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5_yMogCcG7R"
      },
      "source": [
        "# Implementazione PINN con confronto con FD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihmJFZGXfmMs"
      },
      "source": [
        "Innanzitutto inizializzo un sistema di ascisse e ordinate per costruirci la griglia insieme alla configurazione di strati della rete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BbKIBtE33mC"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0, 1, 1000)\n",
        "y = np.linspace(0, 1, 1000)\n",
        "layers = [2, 50, 50, 50, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXZY-QYPf4bk"
      },
      "source": [
        "Sia\n",
        "$$\n",
        "\\Omega = [0,1]\\times[0,1],\n",
        "\\qquad\n",
        "\\partial\\Omega = \\Gamma_D \\cup \\Gamma_N,\n",
        "\\quad\n",
        "\\Gamma_D \\cap \\Gamma_N = \\emptyset,\n",
        "\\quad\n",
        "|\\Gamma_D|>0.\n",
        "$$\n",
        "\n",
        "Si richiami ora la differenza impostazione tra formulazione forte e debole del problema ellittico:\n",
        "\n",
        "**Formulazione forte:**\n",
        "\n",
        "\\begin{cases}\n",
        "-\\Delta u = f, & \\text{in }\\Omega,\\\\[6pt]\n",
        "u = g_D, & \\text{su }\\Gamma_D,\\\\[6pt]\n",
        "\\displaystyle \\frac{\\partial u}{\\partial n} = g_N, & \\text{su }\\Gamma_N.\n",
        "\\end{cases}\n",
        "\n",
        "**Formulazione debole:**\n",
        "\n",
        "\\begin{aligned}\n",
        "&\\text{Trovare }u\\in V\n",
        "=\\bigl\\{v\\in H^1(\\Omega)\\;\\big|\\;v|_{\\Gamma_D}=g_D\\bigr\\}\n",
        "\\quad\\text{tale che}\\\\[4pt]\n",
        "&\\quad\n",
        "\\int_{\\Omega}\\nabla u\\cdot\\nabla v\\,dx\n",
        "=\\int_{\\Omega}f\\,v\\,dx\n",
        "+\\int_{\\Gamma_N}g_N\\,v\\,ds\n",
        "\\quad\\forall\\,v\\in H^1_0(\\Omega;\\Gamma_D),\n",
        "\\end{aligned}\n",
        "\n",
        "\n",
        "dove\n",
        "$$\n",
        "H^1_0(\\Omega;\\Gamma_D)\n",
        "=\\{v\\in H^1(\\Omega)\\mid v|_{\\Gamma_D}=0\\}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gehRkxhVrlUI"
      },
      "outputs": [],
      "source": [
        "#@title Riferimento FD\n",
        "\n",
        "def put_zero_row_in_csr(A, row):\n",
        "    A.data[A.indptr[row]:A.indptr[row+1]] = 0\n",
        "\n",
        "\n",
        "class Geometry2D:\n",
        "    def __init__(self, x, y):\n",
        "        self.x0, self.x1 = x[0], x[-1]\n",
        "        self.y0, self.y1 = y[0], y[-1]\n",
        "        self.set_Ns(len(x), len(y))\n",
        "\n",
        "    def set_Ns(self, Nx, Ny):\n",
        "        self.Nx, self.Ny = Nx, Ny\n",
        "        self.dx = (self.x1 - self.x0) / (Nx - 1)\n",
        "        self.dy = (self.y1 - self.y0) / (Ny - 1)\n",
        "        x = np.linspace(self.x0, self.x1, Nx)\n",
        "        y = np.linspace(self.y0, self.y1, Ny)\n",
        "        self.XX, self.YY = np.meshgrid(x, y, indexing='ij')\n",
        "\n",
        "    def map_2D_to_1D(self, i, j):\n",
        "        return i * self.Ny + j\n",
        "\n",
        "\n",
        "class PoissonProblem2D:\n",
        "    def __init__(self, geometry, boundary=None, f_lambda=None):\n",
        "        self.geometry = geometry\n",
        "        if not boundary:\n",
        "            return AttributeError(\"No boundary conditions specified\")\n",
        "        self.boundary = boundary\n",
        "        self.f_lambda = f_lambda or (lambda x, y: np.ones_like(x))\n",
        "\n",
        "    def assemble(self):\n",
        "        geom = self.geometry\n",
        "        Nx, Ny = geom.Nx, geom.Ny\n",
        "        N = Nx * Ny\n",
        "        dx, dy = geom.dx, geom.dy\n",
        "\n",
        "        main = np.ones(N) * (2/dx**2 + 2/dy**2)\n",
        "        off_x = np.ones(N-Ny) * (-1/dx**2)\n",
        "        off_y = np.ones(N-1)  * (-1/dy**2)\n",
        "        A = sp.diags(\n",
        "            [main, off_x, off_x, off_y, off_y],\n",
        "            [0, -Ny, Ny, -1, 1],\n",
        "            shape=(N, N),\n",
        "            format='csr'\n",
        "        )\n",
        "\n",
        "        X = geom.XX.reshape(-1)\n",
        "        Y = geom.YY.reshape(-1)\n",
        "        f = self.f_lambda(X, Y)\n",
        "\n",
        "        self.A = A\n",
        "        self.f = f\n",
        "        self.apply_BC()\n",
        "\n",
        "    def apply_BC(self):\n",
        "        geom = self.geometry\n",
        "        A = self.A\n",
        "        f = self.f\n",
        "        for side, (btype, bfunc) in self.boundary.items():\n",
        "            if side == 'left':\n",
        "                i_range = [0]\n",
        "                j_range = range(geom.Ny)\n",
        "            elif side == 'right':\n",
        "                i_range = [geom.Nx-1]\n",
        "                j_range = range(geom.Ny)\n",
        "            elif side == 'top':\n",
        "                i_range = range(geom.Nx)\n",
        "                j_range = [geom.Ny-1]\n",
        "            elif side == 'bottom':\n",
        "                i_range = range(geom.Nx)\n",
        "                j_range = [0]\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown side: {side}\")\n",
        "\n",
        "            for i in i_range:\n",
        "                for j in j_range:\n",
        "                    alpha = geom.map_2D_to_1D(i, j)\n",
        "                    x, y = geom.XX[i, j], geom.YY[i, j]\n",
        "                    if btype == 'dirichlet':\n",
        "                        put_zero_row_in_csr(A, alpha)\n",
        "                        A[alpha, alpha] = 1.0\n",
        "                        f[alpha] = bfunc(x, y)\n",
        "                    elif btype == 'neumann':\n",
        "                        put_zero_row_in_csr(A, alpha)\n",
        "                        if side == 'left':\n",
        "                            neighbor = geom.map_2D_to_1D(i+1, j)\n",
        "                            A[alpha, alpha]    = -1.0/geom.dx\n",
        "                            A[alpha, neighbor] =  1.0/geom.dx\n",
        "                        elif side == 'right':\n",
        "                            neighbor = geom.map_2D_to_1D(i-1, j)\n",
        "                            A[alpha, alpha]    =  1.0/geom.dx\n",
        "                            A[alpha, neighbor] = -1.0/geom.dx\n",
        "                        elif side == 'bottom':\n",
        "                            neighbor = geom.map_2D_to_1D(i, j+1)\n",
        "                            A[alpha, alpha]    = -1.0/geom.dy\n",
        "                            A[alpha, neighbor] =  1.0/geom.dy\n",
        "                        elif side == 'top':\n",
        "                            neighbor = geom.map_2D_to_1D(i, j-1)\n",
        "                            A[alpha, alpha]    =  1.0/geom.dy\n",
        "                            A[alpha, neighbor] = -1.0/geom.dy\n",
        "                        f[alpha] = bfunc(x, y)\n",
        "                    else:\n",
        "                        raise ValueError(f\"Boundary type '{btype}' not supported on {side}\")\n",
        "\n",
        "        self.A = A\n",
        "        self.f = f\n",
        "\n",
        "    def solve(self):\n",
        "        if not hasattr(self, 'A') or not hasattr(self, 'f'):\n",
        "            self.assemble()\n",
        "        u_flat = spla.spsolve(self.A, self.f)\n",
        "        return u_flat.reshape(self.geometry.Nx, self.geometry.Ny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5yhkgkk3c85"
      },
      "outputs": [],
      "source": [
        "geom = Geometry2D(x, y)\n",
        "boundary = {\n",
        "    'left':   ('dirichlet', lambda x, y: 0),\n",
        "    'right':  ('dirichlet', lambda x, y: 0),\n",
        "    'top':    ('neumann', lambda x, y: 0),\n",
        "    'bottom': ('neumann', lambda x, y: 0)\n",
        "}\n",
        "poisson = PoissonProblem2D(geom, boundary=boundary)\n",
        "u = poisson.solve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vam3kDRlkGZZ"
      },
      "source": [
        "In generale, una PINN tratta l'equazione in forma forte per cercare di impararne la forma forte con il vincolo di rispetto delle condizioni al bordo (ovviamente per ottenere l'unicità della soluzione).\n",
        "\n",
        "Questo tipo di rete risulta naturale dal concetto di derivata introdotto per il calcolo stesso del \"Backward Pass\" della Backpropagation. Vedi [qui](https://docs.pytorch.org/docs/stable/generated/torch.autograd.grad.html) per ulteriori informazioni.\n",
        "\n",
        "In particolare, la loss che viene utilizzata per trovare la conformazione ottimale di pesi è:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}^{\\text{Tot}} = \\mathcal{L}^{\\text{PDE}} + \\mathcal{L}^{\\text{BC}}\n",
        "$$\n",
        "\n",
        "dove\n",
        "\n",
        "$$\n",
        "\\mathcal{L}^{\\text{PDE}} =  \\text{MSE}(\\mathcal{R}[u^\\theta], 0)\n",
        "$$\n",
        "\n",
        "rappresenta la distanza fra il vettore 0 e il residuo della PDE (ovvero $\\mathcal{R[u^\\theta]}=-\\Delta u^\\theta-f$).\n",
        "\n",
        "Per quanto riguarda $\\mathcal{L}^{\\text{BC}}$, questo rappresenta la distanza fra il valore reale e quello stimato dalla rete fino a quel momento $u^\\theta$.\n",
        "$$\n",
        "\\mathcal{L}^{\\text{BC}} =  \\text{MSE}(u^\\theta(x^b, t^b), g_D(x^b, t^b))\n",
        "$$\n",
        "\n",
        "Con $g_D(x,t)$ funzione di bordo di Dirichlet.\n",
        "\n",
        "Da notare che, tramite lo stesso concetto di derivata usato per il calcolo della forma differenziali, si può facilmente implementare la condizione al bordo di Neumann.\n",
        "\n",
        "Concettualmente la rete viene allenata su $N_i$ punti presi casualmente dall'interno e su $N_j$ punti presi dai bordi.\n",
        "\n",
        "In generale, da qui in poi $f=1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0pykxjkj-zm"
      },
      "outputs": [],
      "source": [
        "class PINNPoisson:\n",
        "    def __init__(\n",
        "        self, x, y, layers, bc, f=None,\n",
        "        epochs=5000, N=(10000, 1000), lr=1e-3, path=None, real_solution = u\n",
        "    ):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.x = np.array(x, dtype=float)\n",
        "        self.y = np.array(y, dtype=float)\n",
        "        self.x_min, self.x_max = self.x.min(), self.x.max()\n",
        "        self.y_min, self.y_max = self.y.min(), self.y.max()\n",
        "        self.bc = bc\n",
        "        self.f = f if f is not None else (lambda x, y: 1.0)\n",
        "        self.epochs = epochs\n",
        "        self.N_f, self.N_b = N\n",
        "        self.path = path\n",
        "        self.model = MLP(layers).to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "        self.U_fd = real_solution\n",
        "        X, Y = np.meshgrid(self.x, self.y, indexing='ij')\n",
        "        XY = np.hstack([X.flatten()[:,None], Y.flatten()[:,None]])\n",
        "        self.grid = torch.tensor(XY, dtype=torch.float32, device=self.device)\n",
        "\n",
        "    def sample_collocation(self):\n",
        "        x = torch.rand(self.N_f,1, device=self.device)*(self.x_max-self.x_min) + self.x_min\n",
        "        y = torch.rand(self.N_f,1, device=self.device)*(self.y_max-self.y_min) + self.y_min\n",
        "        x.requires_grad_(True)\n",
        "        y.requires_grad_(True)\n",
        "        return x, y\n",
        "\n",
        "    def sample_boundary(self):\n",
        "        N_edge = self.N_b // 4\n",
        "        edges = {}\n",
        "\n",
        "        for side in ['left','right','bottom','top']:\n",
        "            bc_type, bc_fn = self.bc[side]\n",
        "\n",
        "            if side == 'left':\n",
        "                y = torch.rand(N_edge,1, device=self.device)*(self.y_max-self.y_min) + self.y_min\n",
        "                x = torch.full_like(y, self.x_min)\n",
        "            elif side == 'right':\n",
        "                y = torch.rand(N_edge,1, device=self.device)*(self.y_max-self.y_min) + self.y_min\n",
        "                x = torch.full_like(y, self.x_max)\n",
        "            elif side == 'bottom':\n",
        "                x = torch.rand(N_edge,1, device=self.device)*(self.x_max-self.x_min) + self.x_min\n",
        "                y = torch.full_like(x, self.y_min)\n",
        "            else:  # top\n",
        "                x = torch.rand(N_edge,1, device=self.device)*(self.x_max-self.x_min) + self.x_min\n",
        "                y = torch.full_like(x, self.y_max)\n",
        "\n",
        "            X_e = torch.cat([x, y], dim=1)\n",
        "            raw_val = bc_fn(x, y)\n",
        "            if torch.is_tensor(raw_val):\n",
        "                val = raw_val\n",
        "                if val.ndim == 1:\n",
        "                    val = val.unsqueeze(1)\n",
        "            else:\n",
        "                val = torch.full((N_edge,1), float(raw_val), device=self.device)\n",
        "\n",
        "            edges[side] = (X_e, bc_type, val)\n",
        "\n",
        "            if bc_type.lower() == 'neumann':\n",
        "                X_e.requires_grad_(True)\n",
        "\n",
        "        return edges\n",
        "\n",
        "    def pde_residual(self, x, y):\n",
        "        u = self.model(torch.cat([x, y], dim=1))\n",
        "        u_x  =  autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
        "\n",
        "        #fare gli altri gradienti (guardare sopra per riferimento)\n",
        "        u_xx =  ???\n",
        "        u_y  =  ???\n",
        "        u_yy =  ???\n",
        "\n",
        "        f_val = self.f(x, y)\n",
        "        if not torch.is_tensor(f_val):\n",
        "            f_val = torch.full_like(u, float(f_val))\n",
        "\n",
        "        residual = ???  # residuo di poisson Δu = -1\n",
        "        return residual\n",
        "\n",
        "    def compute_loss(self):\n",
        "        x_f, y_f = self.sample_collocation()\n",
        "        res   = self.pde_residual(x_f, y_f)\n",
        "        loss_f = self.loss_fn(res, torch.zeros_like(res))\n",
        "        edges = self.sample_boundary()\n",
        "        loss_b = torch.tensor(0.0, device=self.device)\n",
        "        normals = {\n",
        "            'left':   (-1.0,  0.0),\n",
        "            'right':  (+1.0,  0.0),\n",
        "            'bottom': ( 0.0, -1.0),\n",
        "            'top':    ( 0.0, +1.0),\n",
        "        }\n",
        "\n",
        "        for side, (X_e, bc_type, val) in edges.items():\n",
        "            u_pred = self.model(X_e)\n",
        "\n",
        "            if bc_type.lower() == 'dirichlet':\n",
        "\n",
        "                loss_b += ??? #Loss di Dirichlet\n",
        "\n",
        "            else:  # Neumann\n",
        "                grads = autograd.grad(\n",
        "                    u_pred, X_e,\n",
        "                    torch.ones_like(u_pred),\n",
        "                    create_graph=True\n",
        "                )[0]\n",
        "\n",
        "                nx, ny = normals[side]\n",
        "                du_dn = nx*grads[:, 0:1] + ny*grads[:, 1:2]\n",
        "\n",
        "                loss_b += ??? # Loss di Neumann\n",
        "\n",
        "        return loss_f + loss_b, (loss_f.item(), loss_b.item())\n",
        "\n",
        "\n",
        "    def Train(self):\n",
        "        self.model.train()\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            self.optimizer.zero_grad()\n",
        "            total_loss, (lf, lb) = self.compute_loss()\n",
        "            total_loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if epoch % (self.epochs // 10 or 1) == 0:\n",
        "                print(f\"Epoch {epoch}/{self.epochs}, \"\n",
        "                      f\"Loss_f={lf:.3e}, Loss_b={lb:.3e}\")\n",
        "        if self.path:\n",
        "            torch.save(self.model.state_dict(), self.path)\n",
        "\n",
        "    def Pred(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            u_pred = self.model(self.grid).cpu().numpy()\n",
        "        Nx, Ny = len(self.x), len(self.y)\n",
        "        self.U = u_pred.reshape(Nx, Ny)\n",
        "        return self.U\n",
        "\n",
        "    def plot_comparison(self):\n",
        "        fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12, 6))\n",
        "\n",
        "        # PINN\n",
        "        im1 = ax1.imshow(\n",
        "            self.U.T,\n",
        "            origin='lower',\n",
        "            extent=[self.x_min, self.x_max, self.y_min, self.y_max],\n",
        "            aspect='equal'\n",
        "        )\n",
        "        ax1.set_title(\"PINN\")\n",
        "        ax1.set_xlabel(\"x\")\n",
        "        ax1.set_ylabel(\"y\")\n",
        "        fig.colorbar(im1, ax=ax1, label=\"u\")\n",
        "\n",
        "        # FD\n",
        "        im2 = ax2.imshow(\n",
        "            self.U_fd.T,\n",
        "            origin='lower',\n",
        "            extent=[self.x_min, self.x_max, self.y_min, self.y_max],\n",
        "            aspect='equal'\n",
        "        )\n",
        "        ax2.set_title(\"FD\")\n",
        "        ax2.set_xlabel(\"x\")\n",
        "        ax2.set_ylabel(\"y\")\n",
        "        fig.colorbar(im2, ax=ax2, label=\"u\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqWa7Ikpkw-M"
      },
      "outputs": [],
      "source": [
        "pinn = PINNPoisson(x, y, layers, boundary, epochs=5000)\n",
        "pinn.Train()\n",
        "pinn.Pred()\n",
        "pinn.plot_comparison()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwww51jv9nnH"
      },
      "source": [
        "### Esercizio\n",
        "Aggiungi un plot di errore alla classe precedente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK4yqV3lcDjn"
      },
      "source": [
        "# Geometria più complessa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noAib9l5wdtv"
      },
      "source": [
        "Dall’ultimo esperimento si osserva che le PINN non richiedono alcuna discretizzazione esplicita del dominio e sono in grado di trattare geometrie arbitrarie, purché si sappia come campionare separatamente i punti interni e quelli sul bordo.\n",
        "\n",
        "Possiamo sfruttare questo aspetto per valutare la stessa equazione in una geometria più complessa. Come termine di paragone utilizzeremo il metodo degli elementi finiti (FEM), particolarmente adatto a domini complessi.\n",
        "\n",
        "In questo esempio consideriamo un dominio “a ciambella” definito da\n",
        "$$\n",
        "\\Omega \\;=\\;\\bigl\\{(x,y)\\in\\mathbb{R}^2 \\;\\bigm|\\; r_{\\mathrm{in}}\\le \\sqrt{x^2+y^2}\\le r_{\\mathrm{out}}\\bigr\\},\n",
        "$$\n",
        "dove $0<r_{\\mathrm{in}}<r_{\\mathrm{out}}$.  \n",
        "Su $\\Omega$ risolviamo il problema di Poisson con $f(x,y)=1$:\n",
        "\n",
        "\\begin{cases}\n",
        "-\\,\\Delta u(x,y) = 1, & (x,y)\\in\\Omega,\\\\\n",
        "u(x,y) = 0, & (x,y)\\in\\partial\\Omega \\cap \\lbrace x^2+y^2=r_{\\mathrm{out}}^2\\rbrace,\\\\\n",
        "u(x,y) = 1, & (x,y)\\in\\partial\\Omega \\cap \\lbrace x^2+y^2=r_{\\mathrm{in}}^2\\rbrace.\n",
        "\\end{cases}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8-x7GyGZ9UdN"
      },
      "outputs": [],
      "source": [
        "#@title Confronto FEM\n",
        "\n",
        "r_out = 1.0\n",
        "r_in  = 0.2\n",
        "outer = Circle(Point(0.0, 0.0), r_out)\n",
        "inner = Circle(Point(0.0, 0.0), r_in)\n",
        "domain = outer - inner\n",
        "mesh = generate_mesh(domain,  128)\n",
        "\n",
        "V = FunctionSpace(mesh, \"CG\", 1)\n",
        "\n",
        "u0 = Constant(0.0)\n",
        "u1 = Constant(1.0)\n",
        "tol = 1e-3\n",
        "\n",
        "def on_outer(x, on_bnd):\n",
        "    return on_bnd and near(x[0]**2 + x[1]**2, r_out**2, tol)\n",
        "\n",
        "def on_inner(x, on_bnd):\n",
        "    return on_bnd and near(x[0]**2 + x[1]**2, r_in**2, tol)\n",
        "\n",
        "bc_outer = DirichletBC(V, u0, on_outer)\n",
        "bc_inner = DirichletBC(V, u1, on_inner)\n",
        "bcs = [bc_outer, bc_inner]\n",
        "\n",
        "u = TrialFunction(V)\n",
        "v = TestFunction(V)\n",
        "f = Constant(1.0)\n",
        "a = dot(grad(u), grad(v))*dx\n",
        "L = f*v*dx\n",
        "\n",
        "u_h = Function(V)\n",
        "solve(a == L, u_h, bcs)\n",
        "\n",
        "npts = 200\n",
        "x = y = [(-r_out + 2*r_out*(i/(npts-1))) for i in range(npts)]\n",
        "X, Y = mesh.coordinates().T\n",
        "\n",
        "U = np.zeros((npts, npts))\n",
        "for i, xi in enumerate(x):\n",
        "    for j, yj in enumerate(y):\n",
        "        if r_in <= np.hypot(xi, yj) <= r_out:\n",
        "            U[j,i] = u_h(Point(xi, yj))\n",
        "        else:\n",
        "            U[j,i] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok8Ky7gP_0zl"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 1, 200)\n",
        "y = np.linspace(-1, 1, 200)\n",
        "layers = [2, 50, 50, 50, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaj7npEUcuDu"
      },
      "outputs": [],
      "source": [
        "class PINN_Donut:\n",
        "    def __init__(\n",
        "        self,\n",
        "        bcs: dict,\n",
        "        layers=[2,50,50,50,1],\n",
        "        N_f=10000,\n",
        "        N_b=2000,\n",
        "        epochs=5000,\n",
        "        lr=1e-3,\n",
        "        device=None,\n",
        "        real = U\n",
        "    ):\n",
        "\n",
        "        self.bcs = bcs\n",
        "        self.r_in  = bcs['inner']['radius']\n",
        "        self.r_out = bcs['outer']['radius']\n",
        "        self.N_f = N_f\n",
        "        self.N_b = N_b\n",
        "        self.epochs = epochs\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = MLP(layers).to(self.device)\n",
        "        self.optim = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "        self.U_fem = real\n",
        "\n",
        "\n",
        "    def sample_collocation(self, N):\n",
        "        theta = torch.rand(N,1, device=self.device) * 2*np.pi\n",
        "        r = torch.sqrt(\n",
        "            torch.rand(N,1, device=self.device)*(self.r_out**2 - self.r_in**2)\n",
        "            + self.r_in**2\n",
        "        )\n",
        "        x = r*torch.cos(theta)\n",
        "        y = r*torch.sin(theta)\n",
        "        x.requires_grad_(True)\n",
        "        y.requires_grad_(True)\n",
        "        return x, y\n",
        "\n",
        "    def sample_boundary(self, N_per_bound):\n",
        "        out = {}\n",
        "        for name, cfg in self.bcs.items():\n",
        "            θ = torch.rand(N_per_bound,1, device=self.device)*2*np.pi\n",
        "            r = cfg['radius']\n",
        "            xb = r*torch.cos(θ)\n",
        "            yb = r*torch.sin(θ)\n",
        "            xb.requires_grad_(True)\n",
        "            yb.requires_grad_(True)\n",
        "            out[name] = (xb, yb)\n",
        "        return out\n",
        "\n",
        "    def pde_residual(self, x, y):\n",
        "        u = self.model(torch.cat([x, y], dim=1))\n",
        "        u_x = ???\n",
        "        u_y = ???\n",
        "        u_xx = ???\n",
        "        u_yy = ???\n",
        "        residual = ??? # residuo di Poisson Δu = -1\n",
        "        return residual\n",
        "\n",
        "    def compute_loss(self):\n",
        "        xf, yf = self.sample_collocation(self.N_f)\n",
        "        res = self.pde_residual(xf, yf)\n",
        "        loss_f = self.loss_fn(res, torch.zeros_like(res))\n",
        "\n",
        "        loss_b = 0.0\n",
        "        bnds = self.sample_boundary(self.N_b // len(self.bcs))\n",
        "        for name, cfg in self.bcs.items():\n",
        "            xb, yb = bnds[name]\n",
        "            u_pred = self.model(torch.cat([xb, yb], dim=1))\n",
        "\n",
        "            if cfg['type'].lower() == 'dirichlet':\n",
        "                target = torch.full_like(u_pred, float(cfg['value']))\n",
        "                loss_b += self.loss_fn(u_pred, target)\n",
        "\n",
        "            elif cfg['type'].lower() == 'neumann':\n",
        "                r = cfg['radius']\n",
        "                nx = xb / r\n",
        "                ny = yb / r\n",
        "                u_x = autograd.grad(u_pred, xb, grad_outputs=torch.ones_like(u_pred),\n",
        "                                     create_graph=True)[0]\n",
        "                u_y = autograd.grad(u_pred, yb, grad_outputs=torch.ones_like(u_pred),\n",
        "                                     create_graph=True)[0]\n",
        "                dudn = nx*u_x + ny*u_y\n",
        "                target = torch.full_like(dudn, float(cfg['value']))\n",
        "                loss_b += self.loss_fn(dudn, target)\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown BC type {cfg['type']} on '{name}'\")\n",
        "\n",
        "        return loss_f + loss_b, loss_f.item(), loss_b.item()\n",
        "\n",
        "    def Train(self):\n",
        "        self.model.train()\n",
        "        for ep in range(1, self.epochs+1):\n",
        "            self.optim.zero_grad()\n",
        "            loss, lf, lb = self.compute_loss()\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "            if ep % (self.epochs//10 or 1) == 0:\n",
        "                print(f\"[{ep:5d}/{self.epochs}]  Total={loss.item():.2e}  PDE={lf:.2e}  BC={lb:.2e}\")\n",
        "\n",
        "    def Pred(self, npts=200):\n",
        "        xs = np.linspace(-self.r_out, self.r_out, npts)\n",
        "        ys = np.linspace(-self.r_out, self.r_out, npts)\n",
        "        X, Y = np.meshgrid(xs, ys)\n",
        "        U = np.full_like(X, np.nan, dtype=float)\n",
        "\n",
        "        mask = (X**2 + Y**2 >= self.r_in**2) & (X**2 + Y**2 <= self.r_out**2)\n",
        "        pts = np.vstack([X[mask], Y[mask]]).T\n",
        "        with torch.no_grad():\n",
        "            t = torch.tensor(pts, dtype=torch.float32, device=self.device)\n",
        "            u_pred = self.model(t).cpu().numpy().ravel()\n",
        "        U[mask] = u_pred\n",
        "        return xs, ys, U\n",
        "\n",
        "    def plot_comparison(self):\n",
        "        xs, ys, U_pinn = self.Pred(npts)\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        # PINN\n",
        "        pcm1 = ax1.pcolormesh(xs, ys, U_pinn, shading='auto')\n",
        "        ax1.set_aspect('equal')\n",
        "        ax1.set_title(\"PINN\")\n",
        "        ax1.set_xlabel(\"x\")\n",
        "        ax1.set_ylabel(\"y\")\n",
        "        fig.colorbar(pcm1, ax=ax1, label=\"u\")\n",
        "\n",
        "        # FEM\n",
        "        pcm2 = ax2.pcolormesh(xs, ys, self.U_fem, shading='auto')\n",
        "        ax2.set_aspect('equal')\n",
        "        ax2.set_title(\"FEM\")\n",
        "        ax2.set_xlabel(\"x\")\n",
        "        ax2.set_ylabel(\"y\")\n",
        "        fig.colorbar(pcm2, ax=ax2, label=\"u\")\n",
        "\n",
        "        # Error\n",
        "        pcm3 = ax3.pcolormesh(xs, ys, self.U_fem-U_pinn, shading='auto')\n",
        "        ax3.set_aspect('equal')\n",
        "        ax3.set_title(\"Error\")\n",
        "        ax3.set_xlabel(\"x\")\n",
        "        ax3.set_ylabel(\"y\")\n",
        "        fig.colorbar(pcm3, ax=ax3, label=\"u\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvudRqJH8xQd"
      },
      "outputs": [],
      "source": [
        "bcs = {\n",
        "  'inner': {'type':'dirichlet', 'value':1.0, 'radius':0.2},\n",
        "  'outer': {'type':'dirichlet',   'value':0.0, 'radius':1.0},\n",
        "}\n",
        "pinn = PINN_Donut(bcs, layers=[2,50,50,50,1], N_f=20000, N_b=2000, epochs=5000)\n",
        "pinn.Train()\n",
        "pinn.Pred()\n",
        "pinn.plot_comparison()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w94Y6puzzQ_V"
      },
      "source": [
        "# Equazioni dipendenti dal tempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC2YJDkvxwtK"
      },
      "source": [
        "Passiamo ora al caso di equazioni dipendenti dal tempo, in particolare la **heat equation** (parabolica), **Burgers viscoso** (parabolica) e **Burgers inviscido** (iperbolica).\n",
        "\n",
        "Per includere la condizione iniziale, indispensabile per l'unicità della soluzione, si aggiunge una terza parte alla loss:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}^{\\mathrm{IC}}=\\text{MSE}(u^\\theta(x, 0), u_0(x))\n",
        "$$\n",
        "\n",
        "Rendendo quindi la loss totale:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}^{\\text{Tot}} = \\mathcal{L}^{\\text{PDE}} + \\mathcal{L}^{\\text{BC}} + \\mathcal{L}^{\\mathrm{IC}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy3JHxzTuk9Y"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 1, 1000)\n",
        "t = np.linspace(0, 1, 1000)\n",
        "u0 = -np.sin(np.pi*x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKCi6E9RtS3r"
      },
      "outputs": [],
      "source": [
        "def load_model_from_github(model_class, url):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    model = model_class()\n",
        "    model.load_state_dict(torch.load(BytesIO(response.content), map_location=torch.device(device), weights_only=False))\n",
        "    model.to(device)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgtC4-GKzimx"
      },
      "outputs": [],
      "source": [
        "class PINN_B:\n",
        "    def __init__(\n",
        "        self, u0=u0, x=x, t=t, layers=[2,50,50,50,1],\n",
        "        epochs=5000, nu=0.01, equation='burgers',\n",
        "        N = (1000, 1000, 5000), lr = 1e-3, real_solution=None,\n",
        "        bc_type='dirichlet', path=None\n",
        "    ):\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.x = np.array(x, dtype=float)\n",
        "        self.t = np.array(t, dtype=float)\n",
        "        self.x_min, self.x_max = float(self.x.min()), float(self.x.max())\n",
        "        self.t_min, self.t_max = float(self.t.min()), float(self.t.max())\n",
        "\n",
        "        self.u0_np = (u0.copy() if isinstance(u0, np.ndarray)\n",
        "                      else (u0.detach().cpu().numpy() if torch.is_tensor(u0)\n",
        "                            else np.array(u0))).reshape(-1)\n",
        "        self.epochs = epochs\n",
        "        self.nu = nu\n",
        "        self.equation = equation.lower()\n",
        "        self.real_solution = real_solution\n",
        "        self.bc_type = bc_type.lower()\n",
        "        X, T = np.meshgrid(self.x, self.t, indexing='ij')\n",
        "        XT = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "        self.grid = torch.tensor(XT, dtype=torch.float32, device=self.device)\n",
        "        self.N_ic, self.N_bc, self.N_col = N\n",
        "\n",
        "        if not path:\n",
        "            self.model = MLP(layers).to(self.device)\n",
        "        if path:\n",
        "            self.model = load_model_from_github(MLP, path)\n",
        "            self.U_pred = self.Pred()\n",
        "        self.path = path\n",
        "\n",
        "        if self.bc_type == 'dirichlet':\n",
        "            self.bc_left_val, self.bc_right_val = self.u0_np[0], self.u0_np[-1]\n",
        "        elif self.bc_type == 'neumann':\n",
        "            self.bc_left_val, self.bc_right_val = self.u0_np[0], self.u0_np[-1]\n",
        "        elif self.bc_type == 'periodic':\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown bc_type '{bc_type}'\")\n",
        "\n",
        "        self.losses = []\n",
        "        self.loaded = None\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def sample_collocation(self, N):\n",
        "        x = torch.rand(N,1, device=self.device)*(self.x_max-self.x_min) + self.x_min\n",
        "        t = torch.rand(N,1, device=self.device)*(self.t_max-self.t_min) + self.t_min\n",
        "        x.requires_grad_(True)\n",
        "        t.requires_grad_(True)\n",
        "        return x, t\n",
        "\n",
        "    def sample_initial(self, N):\n",
        "        x_ic = torch.rand(N,1, device=self.device)*(self.x_max-self.x_min) + self.x_min\n",
        "        t_ic = torch.zeros_like(x_ic, device=self.device)\n",
        "\n",
        "        u0_ic = np.interp(x_ic.cpu().numpy().flatten(), self.x, self.u0_np)\n",
        "        u0_ic = torch.tensor(u0_ic, dtype=torch.float32, device=self.device).view(-1,1)\n",
        "        return x_ic, t_ic, u0_ic\n",
        "\n",
        "    def sample_boundary(self, N):\n",
        "        t_bc = torch.rand(N,1, device=self.device)*(self.t_max-self.t_min) + self.t_min\n",
        "        if self.bc_type == 'dirichlet':\n",
        "            x_left = torch.full_like(t_bc, self.x_min)\n",
        "            x_right = torch.full_like(t_bc, self.x_max)\n",
        "            Xb = torch.cat([torch.cat([x_left, t_bc], dim=1),\n",
        "                            torch.cat([x_right, t_bc], dim=1)], dim=0)\n",
        "            u_b = torch.cat([\n",
        "                torch.full_like(t_bc, self.bc_left_val),\n",
        "                torch.full_like(t_bc, self.bc_right_val)\n",
        "            ], dim=0).view(-1,1).to(self.device)\n",
        "            return Xb, u_b\n",
        "\n",
        "        else:  # periodic\n",
        "            x_left = torch.full_like(t_bc, self.x_min)\n",
        "            x_right = torch.full_like(t_bc, self.x_max)\n",
        "            X_lb = torch.cat([x_left, t_bc], dim=1)\n",
        "            X_rb = torch.cat([x_right, t_bc], dim=1)\n",
        "            return X_lb, X_rb\n",
        "\n",
        "    def pde_residual(self, x, t):\n",
        "        x = x.clone().requires_grad_(True)\n",
        "        t = t.clone().requires_grad_(True)\n",
        "        u = self.model(torch.cat([x, t], dim=1))\n",
        "        u_t = autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
        "        u_x = ???\n",
        "        u_xx = ???\n",
        "        if self.equation == 'heat':\n",
        "            residual = ??? # inserire residuo per l'equazione del calore\n",
        "        else: # burgers\n",
        "            residual = ??? # inserire residuo per Burgers (viscoso)\n",
        "        return residual\n",
        "\n",
        "    def compute_loss(self):\n",
        "        x_ic, t_ic, u0_ic = self.sample_initial(self.N_ic)\n",
        "        u_pred_ic = self.model(torch.cat([x_ic, t_ic], dim=1))\n",
        "        loss_i = self.loss_fn(u_pred_ic, u0_ic)\n",
        "\n",
        "        if self.bc_type == 'dirichlet':\n",
        "            Xb, u_b = self.sample_boundary(self.N_bc)\n",
        "            if self.bc_type == 'dirichlet':\n",
        "                u_pred_b = self.model(Xb)\n",
        "                loss_b = self.loss_fn(u_pred_b, u_b)\n",
        "            else:\n",
        "                u_pred = self.model(Xb)\n",
        "                x_b = Xb[:, :1]\n",
        "                u_x = autograd.grad(u_pred, x_b, grad_outputs=torch.ones_like(u_pred), create_graph=True)[0]\n",
        "                loss_b = self.loss_fn(u_x, u_b)\n",
        "        else:  # periodic\n",
        "            X_lb, X_rb = self.sample_boundary(self.N_bc)\n",
        "            u_lb = self.model(X_lb)\n",
        "            u_rb = self.model(X_rb)\n",
        "            loss_b = self.loss_fn(u_lb, u_rb)\n",
        "\n",
        "        x_f, t_f = self.sample_collocation(self.N_col)\n",
        "        f_pred = self.pde_residual(x_f, t_f)\n",
        "        loss_f = self.loss_fn(f_pred, torch.zeros_like(f_pred))\n",
        "\n",
        "        total_loss = loss_i + loss_b + loss_f\n",
        "        return total_loss, (loss_i.item(), loss_b.item(), loss_f.item())\n",
        "\n",
        "    def Train(self):\n",
        "        self.model.train()\n",
        "        for ep in range(1, self.epochs + 1):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss, (li, lb, lf) = self.compute_loss()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.losses.append((li, lb, lf, loss.item()))\n",
        "            if ep % (self.epochs // 10 or 1) == 0:\n",
        "                print(f\"PINN: [{ep:5d}/{self.epochs}] | Loss={loss.item():.3e} | PDE={lf:.3e} | BC={lb:.3e} | IC={li:.3e}\")\n",
        "        if self.loaded == False:\n",
        "            torch.save(self.model.state_dict(), self.path)\n",
        "            losses = np.array(self.losses)\n",
        "            np.save(self.path.replace('.pth', '_losses.npy'), losses)\n",
        "\n",
        "    def Pred(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            u_pred = self.model(self.grid).cpu().numpy()\n",
        "        Nx, Nt = len(self.x), len(self.t)\n",
        "        self.U_pred = u_pred.reshape(Nx, Nt).T\n",
        "        return self.U_pred\n",
        "\n",
        "    def plot(self):\n",
        "        fig, ax = plt.subplots(figsize=(8, 5))\n",
        "        im = ax.imshow(self.U_pred, extent=[self.x.min(), self.x.max(), self.t.min(), self.t.max()],\n",
        "                       origin='lower', aspect='auto', cmap='viridis')\n",
        "        label = 'α' if self.equation == 'heat' else 'ν'\n",
        "        ax.set_title(rf\"PINN $\\hat{{u}}(x,t)$ with {label} = {self.nu:.3g}\")\n",
        "        ax.set_xlabel('x'); ax.set_ylabel('t')\n",
        "        fig.colorbar(im, ax=ax, label=r'$\\hat{u}$')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZQSRy0iue3g"
      },
      "outputs": [],
      "source": [
        "PINN_3 = PINN_B(\n",
        "    u0=u0, x=x, t=t, layers=[2, 50, 50, 50, 1],\n",
        "    epochs=5000, nu=0.01, equation='burgers',\n",
        "    N=(1000, 1000, 5000), lr=1e-3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z027LpshuzXP"
      },
      "outputs": [],
      "source": [
        "PINN_3.Train()\n",
        "PINN_3.Pred()\n",
        "PINN_3.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctUgdPkTzO1T"
      },
      "outputs": [],
      "source": [
        "nus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 1e-4, 1e-8, 1e-12]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RObtNb-p1FO8"
      },
      "source": [
        "Si nota però che con $\\nu → 0$ la PINN non è più in grado di stimare lo shock in maniera definita. (Vedi [qui](https://arxiv.org/abs/2211.12393) per i motivi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2s37qlLuEvJ"
      },
      "outputs": [],
      "source": [
        "for nu in nus:\n",
        "    plotting = PINN_B(nu = nu, path=f\"https://raw.github.com/FRAMAX444/PINNs/main/burgers/nu-0/sin_N_C100000_nu{nu}.pth\")\n",
        "    plotting.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti5Mn4-ZzuW2"
      },
      "source": [
        "# Possibili miglioramenti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tind0kId1iH8"
      },
      "source": [
        "Come in \"Improving Weak PINNs for Hyperbolic Conservation Laws: Dual Norm Computation, Boundary Conditions and Systems\" (A. Chaumet, J. Giesselmann) si può riscrivere la PDE in forma debole e passare dalla norma $2$ a $H^{-1}$ (definita come $\\|F\\|_{H^{-1}(\\Omega)}\n",
        ":=\n",
        "\\sup_{\\substack{\\varphi\\in H^{1}_0(\\Omega)\\\\\\|\\varphi\\|_{H^{1}(\\Omega)}=1}}\n",
        "\\bigl\\langle F,\\varphi\\bigr\\rangle$) per riuscire a concentrare lo shock in un unico punto.\n",
        "\n",
        "Ad esempio la $\\mathcal{L}^{\\text{PDE}}$ diventa:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}^{\\text{PDE}} = \\|R[u^\\theta]\\|_{H^{-1}}\n",
        "$$\n",
        "\n",
        "con $R[u^\\theta] = u_t\\varphi - f(u) \\varphi_{x}, \\forall \\varphi \\in H_0^1(\\Omega)$.\n",
        "\n",
        "Ovviamente passando alla forma debole, questa rete incorpora anche un vincolo entropico per scegliere l'unica soluzione fisica. Quindi la loss totale diventa:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\mathcal{L}^{\\text{Tot}}=\\mathcal{L}^{\\text{PDE}}+\\mathcal{L}^{\\text{Ent}}+\\mathcal{L}^{\\text{IC}}+\\mathcal{L}^{\\text{BC}}\n",
        "\\end{equation}\n",
        "\n",
        "(Per definizioni complete e rigorose guardare [qui](https://arxiv.org/abs/2211.12393) o l'implementazione sottostante)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzYOLmd-zzG7"
      },
      "outputs": [],
      "source": [
        "#@title wPINN\n",
        "\n",
        "class wPINN:\n",
        "    def __init__(self, u0=u0, x=x, t=t, layers=[2,50,50,50,1], epochs = 5000, N = (1000, 1000, 5000), lr=1e-3,\n",
        "                 bc_type='dirichlet', lambda_bc=1.0, adv_steps=5, path=None):\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.x = np.array(x, dtype=float)\n",
        "        self.t = np.array(t, dtype=float)\n",
        "        self.u0_np = np.array(u0, dtype=float).reshape(-1)\n",
        "        self.u0 = torch.tensor(self.u0_np, dtype=torch.float32, device=self.device).view(-1,1)\n",
        "\n",
        "        self.u0_x_np = np.gradient(self.u0_np, self.x)\n",
        "\n",
        "        self.u0 = torch.tensor(self.u0_np,  dtype=torch.float32, device=self.device).view(-1,1)\n",
        "        self.u0_x = torch.tensor(self.u0_x_np, dtype=torch.float32, device=self.device).view(-1,1)\n",
        "\n",
        "        self.t_min, self.t_max = float(self.t[0]), float(self.t[-1])\n",
        "        self.x_min, self.x_max = float(self.x[0]), float(self.x[-1])\n",
        "\n",
        "        self.lambda_bc = lambda_bc\n",
        "        self.adv_steps = adv_steps\n",
        "\n",
        "        self.u_net   = MLP(layers).to(self.device)\n",
        "        self.path = path\n",
        "        self.losses = []\n",
        "        self.loaded = None\n",
        "\n",
        "        T_mesh, X_mesh = np.meshgrid(self.t, self.x, indexing='ij')  # shapes (nt,nx)\n",
        "        stacked = np.hstack((T_mesh.flatten()[:,None], X_mesh.flatten()[:,None]))  # (nt*nx,2)\n",
        "        self.grid = torch.tensor(stacked, dtype=torch.float32, device=self.device)\n",
        "        self.U_pred = None\n",
        "        self.N_ic, self.N_bc, self.N_int = N\n",
        "        self.epochs = epochs\n",
        "        self.bc_type = bc_type.lower()\n",
        "\n",
        "        if not path:\n",
        "            self.u_net = MLP(layers).to(self.device)\n",
        "        if path:\n",
        "            self.u_net = load_model_from_github(MLP, path)\n",
        "            self.U_pred = self.Pred()\n",
        "        self.path = path\n",
        "\n",
        "        self.phi_net = MLP(layers).to(self.device)\n",
        "        self.xi_net  = MLP(layers).to(self.device)\n",
        "\n",
        "        self.opt_u   = torch.optim.Adam(self.u_net.parameters(),   lr=lr)\n",
        "        self.opt_phi = torch.optim.Adam(self.phi_net.parameters(), lr=lr)\n",
        "        self.opt_xi  = torch.optim.Adam(self.xi_net.parameters(),  lr=lr)\n",
        "\n",
        "    def sample_collocation(self, N):\n",
        "        t = torch.rand(N,1, device=self.device)*(self.t_max-self.t_min) + self.t_min\n",
        "        x = torch.rand(N,1, device=self.device)*(self.x_max-self.x_min) + self.x_min\n",
        "        t.requires_grad_(True); x.requires_grad_(True)\n",
        "        return t, x\n",
        "\n",
        "    def flux(self, u): return 0.5*u**2\n",
        "\n",
        "    def cutoff(self, x):\n",
        "        center = (self.x_min + self.x_max)/2\n",
        "        radius = (self.x_max - self.x_min)/2\n",
        "        return 1 - ((x - center)/radius)**2\n",
        "\n",
        "    def pde_pairing(self, t, x):\n",
        "        inp = torch.cat([t,x], dim=1)\n",
        "        u = self.u_net(inp)\n",
        "        u_t = autograd.grad(u, t, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        f = self.flux(u)\n",
        "        f_x = autograd.grad(f, x, torch.ones_like(f), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        phi_raw = self.phi_net(inp)\n",
        "        phi = phi_raw * self.cutoff(x)\n",
        "        phi_x = autograd.grad(phi, x, torch.ones_like(phi), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        return u_t*phi - f*phi_x, phi_x\n",
        "\n",
        "    def entropy_pairing(self, t, x):\n",
        "        inp = torch.cat([t,x], dim=1)\n",
        "        u = self.u_net(inp)\n",
        "        e = 0.5*u**2\n",
        "        q = (1./3.)*u**3\n",
        "        e_t = autograd.grad(e, t, torch.ones_like(e), retain_graph=True, create_graph=True)[0]\n",
        "        q_x = autograd.grad(q, x, torch.ones_like(q), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        res_pos = torch.relu(e_t + q_x)\n",
        "        xi_raw = self.xi_net(inp)\n",
        "        xi = xi_raw * self.cutoff(x)\n",
        "        xi_x = autograd.grad(xi, x, torch.ones_like(xi), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        return res_pos*xi, xi_x\n",
        "\n",
        "    def compute_boundary_loss(self):\n",
        "        t_bc = torch.rand(self.N_bc, 1, device=self.device) * (self.t_max - self.t_min) + self.t_min\n",
        "\n",
        "        t_bc_cat = torch.cat([t_bc, t_bc], dim=0)\n",
        "        x_bc = torch.cat([torch.full_like(t_bc, self.x_min),\n",
        "                          torch.full_like(t_bc, self.x_max)], dim=0)\n",
        "        X_bc = torch.cat([t_bc_cat, x_bc], dim=1)\n",
        "\n",
        "        u_pred = self.u_net(X_bc)\n",
        "\n",
        "        if self.bc_type == 'dirichlet':\n",
        "            u_left  = self.u0[0]\n",
        "            u_right = self.u0[-1]\n",
        "            u_true  = torch.cat([\n",
        "                u_left .expand(self.N_bc,1),\n",
        "                u_right.expand(self.N_bc,1)\n",
        "            ], dim=0)\n",
        "            return (u_pred - u_true).pow(2).mean()\n",
        "\n",
        "        elif self.bc_type == 'neumann':\n",
        "            Xb = X_bc.clone().requires_grad_(True)\n",
        "            u_b = self.u_net(Xb)\n",
        "            u_x = autograd.grad(u_b,\n",
        "                                Xb[:,1:2],\n",
        "                                grad_outputs=torch.ones_like(u_b),\n",
        "                                create_graph=True)[0]\n",
        "\n",
        "            ux_left  = self.u0_x[0]\n",
        "            ux_right = self.u0_x[-1]\n",
        "            g_true   = torch.cat([\n",
        "                ux_left .expand(self.N_bc,1),\n",
        "                ux_right.expand(self.N_bc,1)\n",
        "            ], dim=0)\n",
        "            return (u_x - g_true).pow(2).mean()\n",
        "\n",
        "        elif self.bc_type == 'periodic':\n",
        "            X_lb = torch.cat([t_bc, torch.full_like(t_bc, self.x_min)], dim=1)\n",
        "            X_rb = torch.cat([t_bc, torch.full_like(t_bc, self.x_max)], dim=1)\n",
        "            return (self.u_net(X_lb) - self.u_net(X_rb)).pow(2).mean()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown bc_type {self.bc_type}\")\n",
        "\n",
        "\n",
        "    def Train(self):\n",
        "        for epoch in range(1, self.epochs+1):\n",
        "            for _ in range(self.adv_steps):\n",
        "                t_int, x_int = self.sample_collocation(self.N_int)\n",
        "                r_pde, phi_x = self.pde_pairing(t_int, x_int)\n",
        "                Lu_PDE = (r_pde - 0.5*phi_x**2).mean()\n",
        "                r_ent, xi_x = self.entropy_pairing(t_int, x_int)\n",
        "                L_ent = (r_ent - 0.5*xi_x**2).mean()\n",
        "\n",
        "                self.opt_phi.zero_grad(); (-Lu_PDE).backward(retain_graph=True); self.opt_phi.step()\n",
        "                self.opt_xi.zero_grad(); (-L_ent).backward(retain_graph=True); self.opt_xi.step()\n",
        "\n",
        "            t_int, x_int = self.sample_collocation(self.N_int)\n",
        "            r_pde, phi_x = self.pde_pairing(t_int, x_int)\n",
        "            Lu_PDE = (r_pde - 0.5*phi_x**2).mean()\n",
        "            r_ent, xi_x = self.entropy_pairing(t_int, x_int)\n",
        "            L_ent = (r_ent - 0.5*xi_x**2).mean()\n",
        "\n",
        "            x_ic = torch.rand(self.N_ic,1, device=self.device)*(self.x_max-self.x_min)+self.x_min\n",
        "            t_ic = torch.zeros_like(x_ic, device=self.device)\n",
        "            u_ic = self.u_net(torch.cat([t_ic, x_ic], dim=1))\n",
        "            u0_ic = np.interp(x_ic.cpu().numpy().flatten(), self.x, self.u0_np)\n",
        "            u0_ic = torch.tensor(u0_ic, dtype=torch.float32, device=self.device).view(-1,1)\n",
        "            L_ic = (u_ic - u0_ic).pow(2).mean()\n",
        "\n",
        "            L_bc = self.compute_boundary_loss()\n",
        "            loss = Lu_PDE + L_ent + self.lambda_bc*(L_ic + L_bc)\n",
        "            self.opt_u.zero_grad(); loss.backward(); self.opt_u.step()\n",
        "\n",
        "            self.losses.append((Lu_PDE.item(), L_ent.item(), L_ic.item(), L_bc.item(), loss.item()))\n",
        "\n",
        "            if epoch % (self.epochs//10 or 1) == 0:\n",
        "                print(f\"wPINN: [{epoch}/{self.epochs}] | Loss={loss.item():.2e} | PDE={Lu_PDE.item():.2e} | Ent={L_ent.item():.2e} | BC={L_bc.item():.2e} | IC={L_ic.item():.2e}\")\n",
        "        if self.loaded == False:\n",
        "            torch.save(self.u_net.state_dict(), self.path)\n",
        "            losses = np.array(self.losses)\n",
        "            np.save(self.path.replace('.pth', '_losses.npy'), losses)\n",
        "\n",
        "    def Pred(self):\n",
        "        self.u_net.eval()\n",
        "        with torch.no_grad():\n",
        "            u_pred = self.u_net(self.grid).cpu().numpy()\n",
        "        nt, nx = len(self.t), len(self.x)\n",
        "        self.U_pred = u_pred.reshape(nt, nx)\n",
        "        return self.U_pred\n",
        "\n",
        "    def plot(self):\n",
        "        fig, ax = plt.subplots(figsize=(8,5))\n",
        "        im = ax.imshow(self.U_pred, extent=[self.x.min(), self.x.max(),\n",
        "                                            self.t.min(), self.t.max()],\n",
        "                       origin='lower', aspect='auto', cmap='viridis')\n",
        "        ax.set_title(r\"wPINN $\\hat{u}(x,t)$\")\n",
        "        ax.set_xlabel('x'); ax.set_ylabel('t')\n",
        "        fig.colorbar(im, ax=ax, label=r'$\\hat{u}$')\n",
        "        plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vVcS4ow0ibl"
      },
      "outputs": [],
      "source": [
        "wpinn = wPINN(path=\"https://raw.github.com/FRAMAX444/PINNs/main/burgers/trained_models/wpinn_burgers_inviscid_1_finale.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOUdK2Rj03C0"
      },
      "outputs": [],
      "source": [
        "wpinn.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlTzxSXz8UxO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
