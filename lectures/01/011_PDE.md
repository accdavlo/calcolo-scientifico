---
marp: true
math: mathjax
---
<!--
title: Lecture 011 PDE
paginate: true
_class: titlepage
-->

# Partial Differential Equations

---

## PDE

<style scoped>section{font-size:23px;padding:50px;padding-top:50px}</style>

Given a domain $\Omega \in \mathbb R ^{d}$ where $d>1$, we seek for $u:\Omega \to \mathbb R^s$ where $s\in \mathbb N_0$, solution of a **stationary PDE** of order $k$:
$$F(x,t,u, \nabla u \dots, \nabla^{(k-1)}u,\nabla^{(k)}u, g)=0$$
with $g:\Omega \to \mathbb R^s$ a given function. Or, more explicitely as
$$\mathcal{P}(u,g) \equiv F(x, u, \frac{\partial u}{\partial x_1},\dots, \frac{\partial u}{\partial x_d}, \frac{\partial^2 u}{\partial x_1 \partial x_1}, \dots, \frac{\partial^{p_1+\dots+p_d} u}{\partial^{p_1} x_1 \, \partial^{p_2} x_2 \dots \partial^{p_d} x_d }, g  )=0,$$
where $p_1+ \dots + p_d\leq k$.

A non stationary PDE of order $k$ reads: find $u:\Omega \times [0,T] \to \mathbb R^{s}$
$$\begin{equation}\mathcal{P}(u,g) \equiv F(x,t, u, \frac{\partial u}{\partial t}, \frac{\partial u}{\partial x_1},\dots, \frac{\partial u}{\partial x_d}, \frac{\partial^2 u}{\partial x_1 \partial x_1}, \dots, \frac{\partial^{p_0+p_1+\dots+p_d} u}{\partial^{p_0}t \,\partial^{p_1} x_1  \dots \partial^{p_d} x_d }, g  )=0,\end{equation}$$
where $p_0+ \dots + p_d\leq k$.

A classical solution of a PDE is a function $u\in \mathcal{C}^k(\Omega \times [0,T])$ that solves the previous equation. 

---
<style scoped>section{font-size:23px;padding:50px;padding-top:0px}</style>

### Definition
If the PDE can be written in the form 
$$
\mathcal{P}(u,g) = a(x) u + b_0(x) \partial_t u + b_1(x) \partial_{x_1}u +\dots + b_d(x) \partial_{x_d}u + c_{\alpha(2,0,\dots,0)} \partial_{tt} u +\dots + \gamma_{\alpha(p_0,\dots ,p_d)} \frac{\partial^{p_0+\dots +p_d} u}{\partial^{p_0}t\,\partial^{p_1}x_1\dots \partial^{p_d}x_d}+\dots -g=0,
$$
i.e., if the coefficitents of the unknown $u$ and of its derivatives depend only on the independent variables $(t,x)$, then the PDE is **linear**. Else, it is **nonlinear**.

### Definitions
Consider a nonlinear PDE of order $k$
* if the coefficients of the derivatives of order $k$ depend only on the indepenedent variables $(t,x)$, then the PDE is **semilinear**;
* if the coefficients of the derivates of order $k$ depend on the independent variables  $(t,x)$ and on the partial derivatives of $u$ of order at most $k-1$, then the PDE is **quasi-linear**;
* if it's not quasi-linear, its **fully nonlinear**.


--- 
<style scoped>section{font-size:23px;padding:50px;padding-top:0px}</style>

### Examples

* Reaction-advection-diffusion equation
    $$ \partial_t u = u_{xx } + c u_x + u^2,$$
    is semilinear.
* Inviscid Burgers' equation
    $$
    \partial_t u + u u_x =0,
    $$
    is quasi-linear but not semilinear.
* The Korteweg-de Vries (KdV) equation
    $$
    \partial_t u + u \partial_x u + \partial_{xxx} u =0,
    $$
    is semilinear.
* The Monge-Ampère equation
    $$
    u_{xx}u_{yy} - (u_{xy})^2 =0
    $$
    is fully nonlinear.

---
<style scoped>section{font-size:23px;padding:50px;padding-top:0px}</style>

## First order linear PDE , a.k.a. transport equation

$$ u_t + u_x=0 $$
How do I found a general solution?

Let's try this change of variables 
$$(x,t) \to(\xi, \eta), \qquad \xi(x,t) = x+t,\, \eta(x,t)= x-t $$
with inverse
$$ x = \frac{\xi+\eta}{2}, t = \frac{\xi-\eta}{2}.$$
I substitute the new variables: $v(\xi,\eta):=u(x(\xi,\eta),t(\xi,\eta))$
$$\begin{align}u_x = v_\xi \xi_x + v_\eta \eta_x = v_\xi + v_\eta\\
u_t = v_\xi \xi_t + v_\eta \eta_t = v_\xi -v_\eta\end{align}$$
obtaining a new PDE
$$0=u_t+u_x = 2 v_\xi \Longleftrightarrow v_\xi=0.$$
Implica che $v(\xi,\eta)=f(\eta)$ with $f\in\mathcal{C}^1(\mathbb R)$. Going back to the original variables
$$u(x,t) = v(\xi(x,t),\eta(x,t)) = f(\xi(x,t))=f(x-t)$$

---
# Characteristic lines
<style scoped>section{padding-top:30px;align-content: start;}</style>

$$u_t+u_x=0, \qquad u(x,t) = v(\xi(x,t),\eta(x,t)) = f(\xi(x,t))=f(x-t).$$
$$X_{x_0}(t) = x_0+t$$

---

# Generalization to different coefficients
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

$$a(t,x)u_t+b(t,x)u_x+cu(t,x)=g(t,x), (t,x)\in\Omega\subset\mathbb R^2.$$
Well defined (non-singular and $\mathcal{C}^1$) transformation $(t,x) \Leftrightarrow (\xi,\eta)$, i.e.,
$$\left| \frac{\partial (\xi,\eta)}{\partial(t,x)}\right| := \left| \begin{pmatrix} \xi_t &\xi_x\\ \eta_t & \eta_x \end{pmatrix}\right| = \xi_t\eta_x - \xi_x \eta_t \neq 0.$$
Change of variables: $u_t=v_\xi \xi_t + v_\eta\eta_t , \,u_x = v_\xi \xi_x + v_\eta \eta_x,$ giving
$$(a \xi_t + b \xi_x) v_\xi + (a\eta_t +b\eta_x)v_\eta +cv = g(t(\xi,\eta),x(\xi,\eta))$$
Goal: simplify the previous equation, we choose $\eta$ such that
$$a\eta_t + b \eta_x =0,$$
so that we obtain an ODE for every $\eta$
$$v_\xi + \frac{c}{a \xi_t + b \xi_x}v = \frac{g(t(\xi,\eta),x(\xi,\eta))}{a \xi_t + b \xi_x}.$$

---
# Generalization to different coefficients
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

To obtain $a\eta_t + b \eta_x =0$, one should notice that, w.l.o.g., we are looking for a curve $x(t)$ such that $\eta(t,x(t)) = \eta_0$ constant for every $t$.
$$0= \frac{d \eta(t,x(t))}{dt} =\eta_t + \eta_x \frac{\partial x}{\partial t} \Longrightarrow \frac{\eta_t}{\eta_x} = -\partial_t x(t)$$ 
Hence, we have
$$\frac{\eta_t}{\eta_x} = -\frac{b}{a} \Longleftrightarrow \partial_t x(t) = -\frac{b}{a}.$$

Integrating this equation, one obtains the curve $x(t)$, leading to the definition of $\eta(t,x)$ solving for the constant $\eta_0$.


---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

# Example
$$xu_t-tu_x=1$$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

# Example
$$xu_t-tu_x=1$$
$$\begin{align}
&(x\xi_t -t\xi_x)v_\xi +(x\eta_t -t \eta_x)v_\eta =1\\
&(x\eta_t -t \eta_x)=0\\
&\frac{dx}{dt}=-\frac{t}{x}\\
&\int x\,dx=\int -t\,dt\\
&x=\sqrt{\eta_0^2-t^2}\\
&\eta(t,x):=\sqrt{t^2+x^2} & \eta_t = \frac{t}{\sqrt{t^2+x^2}}, \quad & \eta_x =  \frac{x}{\sqrt{t^2+x^2}},\\
&\xi(t,x)=\arctan (x/t) & \xi_t = \frac{t^2}{x^2+t^2}\frac{-x}{t^2} = -\frac{x}{x^2+t^2}, \quad & \xi_x = \frac{t}{x^2+y^2},\\
& t=\eta \cos(\xi),\,x = \eta \sin(\xi),\\
&\underbrace{(-\eta \sin(\xi) \frac{\eta \sin(\xi)}{\eta^2} -\eta\cos(\xi)\frac{\eta\cos(\xi)}{\eta^2})}_{=-1} v_\xi=1, &v=-\xi+f(\eta) \qquad u=-\arctan(x/t)&+f(x^2+y^2).
\end{align}
$$

---

## Homework

* Solve $u_x-2u_y=0$
* Solve $yu_x-xu_y+uy=xy$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>
# Second order linear PDE in 2D

Consider the PDE on $\Omega\subset \mathbb{R}^2$
$$\mathcal{P}(u,g) = A \partial_{xx}u+ B u_{xy} + C u_{yy} + Du_x + Eu_y +Fu-g=0\quad \forall (x,y) \in \Omega$$
where $u\in \mathcal{C}^2(\Omega)$ and $A,B,C\in \mathcal C^2(\Omega)$ and they do not vanish simultaneously. Let's **classify** the PDE depending on the *discriminant* 
$$
\Delta := B^2-4AC.
$$
## Definition
* If $\Delta>0$ the PDE is said to be hyperbolic (at a point $(x,y)$)
* If $\Delta=0$ the PDE is said to be parabolic (at a point $(x,y)$)
* If $\Delta<0$ the PDE is said to be elliptic (at a point $(x,y)$)


---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

* ### Hyperbolic example: wave equation
    $$ \partial_{tt} u - c \partial_{xx} u =0 \text{ with }c>0$$
    Indeed, $\Delta = 4c>0.$

* ### Parabolic example: heat equation
    $$ \partial_{t} u - c \partial_{xx} u =0 \text{ with }c>0$$
    Indeed, $\Delta = 0.$

* ### Elliptic example: Poisson equation
    $$ - c \partial_{xx} u -c\partial_{yy}u =-c \Delta u =f \text{ with }c>0$$
    Indeed, $\Delta = -4c^2<0.$

* ### Changing sign example: Tricomi equation
    $$y u_{xx}+ u_{yy}=0$$
    $\Delta = -4y.$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

### Theorem
The sign of the discriminant $\Delta$ is invariant under smooth non-singular transformation of coordinates (i.e. under a change of variables).

#### Proof 1/2
We focus only on the second order terms as the first order ones do not contribute to the discriminant.
Suppose we perform a smooth change of variables $(x,y) \mapsto (\xi,\eta)$, given by a diffeomorphism.
Under this transformation, the second-order derivatives transform as follows:
$$\begin{equation}
    u_{xx} = \alpha^2 u_{\xi\xi} + 2\alpha\beta u_{\xi\eta} + \beta^2 u_{\eta\eta},
\end{equation}$$
$$\begin{equation}
    u_{xy} = \alpha\gamma u_{\xi\xi} + (\alpha\delta + \beta\gamma) u_{\xi\eta} + \beta\delta u_{\eta\eta},
\end{equation}$$
$$\begin{equation}
    u_{yy} = \gamma^2 u_{\xi\xi} + 2\gamma\delta u_{\xi\eta} + \delta^2 u_{\eta\eta},
\end{equation}$$
where
$$\begin{equation}
    \alpha = \frac{\partial x}{\partial \xi}, \quad \beta = \frac{\partial x}{\partial \eta}, \quad \gamma = \frac{\partial y}{\partial \xi}, \quad \delta = \frac{\partial y}{\partial \eta}.
\end{equation}$$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

#### Proof 2/2

Rewriting the PDE in the new coordinates, the transformed coefficients $A', B', C'$ are given by
$$\begin{equation}
    A' = A\alpha^2 + 2B\alpha\gamma + C\gamma^2,
\end{equation}$$
$$\begin{equation}
    B' = A\alpha\beta + B(\alpha\delta + \beta\gamma) + C\gamma\delta,
\end{equation}$$
$$\begin{equation}
    C' = A\beta^2 + 2B\beta\delta + C\delta^2.
\end{equation}$$

Now, computing the transformed discriminant:
$$\begin{align}
    \Delta' &= B'^2 - A'C' \\
    &= (A\alpha\beta + B(\alpha\delta + \beta\gamma) + C\gamma\delta)^2 \\
    &\quad - (A\alpha^2 + 2B\alpha\gamma + C\gamma^2)(A\beta^2 + 2B\beta\delta + C\delta^2).
\end{align}$$
Expanding both terms and simplifying, we find that
$$\begin{equation}
    \Delta' = (B^2 - AC)(\alpha\delta - \beta\gamma)^2 = \Delta \det(J)^2,
\end{equation}$$
where $J$ is the Jacobian matrix of the transformation. Since $\det(J)^2 \geq 0$, the sign of $\Delta$ remains unchanged. This proves the invariance of the discriminant sign under a change of variables.


---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Hyperbolic canonical form

Consider the wave equation
$$\partial_{tt} u- c \partial_{xx} u =0$$
with $c>0$. We can find a change of variables $(x,t) \mapsto (\xi,\eta)$ such that the PDE simplifies to
$$\partial_{\xi\eta} v =0.$$
The map is defined by 
$$\eta=x+t,\quad \xi = x-t.$$
This is the canonical form of a hyperbolic PDE. The general solution is given integrating in $\xi$ and then in $\eta$, i.e.,
$$v(\xi,\eta) = \int^{\xi} \int^{\eta} \partial_{wz} v(w,z)\, dz\, dw = \int^{\xi} f(w)  dw = F(\xi) + G(\eta) ,$$
where $\partial_\xi F(\xi) = f(\xi)$.
So, the general solution of the wave equation is 
$$ u(x,t) = F(x-t) + G(x+t).$$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Hyperbolic canonical form: can we always get it?
Consider just the second order terms of the hyperbolic PDE $\Delta = B^2-4AC>0$.
$$ A \partial_{xx}u+ B u_{xy} + C u_{yy} =0.$$
We look for a change of variables $(x,y) \mapsto (\xi,\eta)$ such that the PDE simplifies to 
$$\partial_{\xi\eta} v =0.$$
The transformation can be applied noting that
$$
\begin{align}
&u_{xx} = v_{\xi\xi}(\xi_x)^2 + 2v_{\xi\eta}\xi_x\eta_x + v_{\eta\eta}(\eta_x)^2,\\
&u_{xy} = v_{\xi\xi}\xi_x\xi_y + v_{\xi\eta}(\xi_x\eta_y+\xi_y\eta_x) + v_{\eta\eta}\eta_x\eta_y,\\
&u_{yy} = v_{\xi\xi}(\xi_y)^2 + 2v_{\xi\eta}\xi_y\eta_y + v_{\eta\eta}(\eta_y)^2,
\end{align}
$$

The transformed PDE reads
$$ (A\xi_x^2+B\xi_x\xi_y + C \xi_y^2)v_{\xi\xi} + (2A\xi_x\eta_y + B(\xi_x\eta_y+\xi_y\eta_x )+ 2C\xi_y\eta_x)v_{\xi\eta} + (A\eta_x^2+B\eta_x\eta_y+C\eta_y^2)v_{\eta\eta}=0.$$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>
Computation space

---
<style scoped>section{font-size:20px;padding-top:30px;align-content: start;}</style>
$$ (A\xi_x^2+B\xi_x\xi_y + C \xi_y^2)v_{\xi\xi} + (2A\xi_x\eta_y + B(\xi_x\eta_y+\xi_y\eta_x )+ 2C\xi_y\eta_x)v_{\xi\eta} + (A\eta_x^2+B\eta_x\eta_y+C\eta_y^2)v_{\eta\eta}=0.$$
We want to find the change of variables such that
$$
\begin{align}
\begin{cases}
A\xi_x^2+B\xi_x\xi_y + C \xi_y^2 = 0\\
A\eta_x^2+B\eta_x\eta_y+C\eta_y^2=0
\end{cases}
\end{align}
$$
These are first order PDE, so we are looking for characteristics curves such that $\xi(x,y)=\text{const}$, if we find a curve, for example $y(x)$ such that $\xi(x,y(x))=\text{const}$, then
$$\frac{d\xi}{dx} = \frac{\partial \xi}{\partial x} + \frac{\partial \xi}{\partial y}\frac{dy}{dx} =0 \Longrightarrow \frac{dy}{dx} = -\frac{\partial_x \xi}{\partial_y \xi}.$$
From the first PDE, we then get
$$
A\left(\frac{dy}{dx}\right)^2 + B\frac{dy}{dx} + C =0,
$$
which is called the characteristic equation for the original PDE. This is quadratic equation in $\frac{dy}{dx}$ with $\Delta = B^2-4AC>0$. The two distinct solutions are
$$
\frac{dy}{dx} = \frac{-B\pm \sqrt{\Delta}}{2A}.
$$
From this we can get the transformation $(x,y) \mapsto (\xi,\eta)$ as we did in the linear PDE.

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>
Computation space

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Example 
$$u_{tt}+u_{tx} =0$$

$$
\begin{align}
(\xi_t^2+\xi_t\xi_x)u_{\xi\xi} + (2\xi_t\eta_t +\xi_t\eta_x+\xi_x\eta_t)u_{\xi\eta} + (\eta_t^2+\eta_t\eta_x)u_{\eta\eta} =0\\
\end{align}
$$
The equations for $\xi$ and $\eta$ are the same equations.
We look for a curve $y(x)$ such that $\xi(x,y(x))=\text{const}$, i.e., $\xi(x,y(x)) = x+y(x)=\text{const}$ and that
$$
\begin{align}
&\xi_t^2+\xi_t\xi_x =0\\
&\frac{\xi_t^2}{\xi_x^2}+\frac{\xi_t}{\xi_x} =0\\
&\left(\frac{dx}{dt}\right)^2-\frac{dx}{dt} =0\\
&\frac{dx}{dt}=\begin{cases}
0\\
1
\end{cases}
 \Longrightarrow x(t) = \begin{cases}
\xi_0\\
\eta_0+t
\end{cases}\\
\Longrightarrow & \eta=x-t, \quad \xi=x.
\end{align}
$$

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

### What if we try to do the same with a parabolic PDE?

$$
\frac{dx}{dt} = -\frac{B\pm \sqrt{\Delta}}{2A}=-\frac{B}{2A}.
$$
There is only one characteristic curve. So, choosing $\xi = 2A x + B t$ and $\eta = x$ we get the canonical form
$$
A\frac{\partial^2 v}{\partial \xi^2} =0,
$$
with the general solution $v(\xi,\eta) = F(\eta) + \xi G(\eta)$.

### What if we try to do the same with an elliptic PDE?
There is no characteristics that is conserved. But, one can instead eliminate the coefficient of $u_{\xi\eta}$ to obtain the canonical form for the elliptic PDE. Using $\eta=t$ and $\xi=\frac{2Ax-Bt}{\sqrt{\Delta}}$, we get
$$
A\left(\frac{\partial^2 v}{\partial \xi^2} + \frac{\partial^2 v}{\partial \eta^2}\right) =0.
$$


---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

# Existence, uniqueness and well-posedness
For the PDEs above we have found classes of solutions. How can we find unique solutions to specific problems? What should we need to specify?
## Definition (Cauchy problem)
Consider a PDE of order $k$ in $\Omega\subset \mathbb R^d$ and let $S$ be a given smooth surface on $\mathbb R^d$. Let also $n = n(x)$ denote the unit normal vector to the surface $S$ at a point $x = (x_1 , x_2 ,\dots, x_d )\in S$. Suppose that on any point $x$ of the surface $S$ the values of the solution u and of all its directional derivatives up to order $k − 1$ in the direction of $n$ are given, i.e., we are given functions $f_0 , f_1 , \dots, f_{k−1}: S \to \mathbb R$ such that
$$u(x) = f_0 (x),
\text{ and }
\frac{\partial u}{\partial n}(x) = f_1(x),
\text{ and }
\frac{\partial^2 u}{\partial n^2}(x) = f_2 (x), \dots,
\text{ and }
\frac{\partial^{k-1} u}{\partial n^{k-1}}(x) = f_{k−1} (x).
$$
The **Cauchy problem** consists of finding the unknown function(s) $u$ that satisfy simultaneously the PDE and the conditions above, which are called the **initial conditions** (ICs) and the given functions $f_0 , f_1 , \dots , f_{k−1}$, will be referred to as the initial data.
According to the role of the ICs they can be called also **boundary conditions** (BCs).

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Examples (Cauchy problem for transport equation)
$$
\begin{align}
\begin{cases}
    u_t+u_x = 0, \quad (x,t)\in\mathbb R^2,\\
    u(0,x) = \sin(x), \quad x\in\mathbb R.
\end{cases}
\end{align}
$$
Here, $S=\lbrace (t,x)\in \mathbb R^2: t=0  \rbrace$.
The general solution of the transport equation is $u(x,t) = f(x-t)$, so that the initial condition reads $f(x) = \sin(x)$, i.e., $u(x,t) = \sin(x-t)$.

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Examples (Cauchy problem for wave equation)

$$
\begin{align}
\begin{cases}
    u_{tt}-u_{xx} = 0, \quad (x,t)\in\mathbb R^2,\\
    u(t,0) = \sin(t), \quad t\in\mathbb R,\\
    u_x(t,0) = 0, \quad t\in\mathbb R.
\end{cases}
\end{align}
$$
In this case, $S=\lbrace (t,x)\in \mathbb R^2: x=0  \rbrace$ and $n=(n_t,n_x)=(0,-1)$. The general solution of the wave equation is $u(t,x) = f(x-t) + g(x+t)$, so that the initial (boundary) conditions read $f_0(t) = \sin(t)$ and $f_1(t) = 0$, so
$$
\begin{align}
    \begin{cases}
        f(-t)+g(t) = \sin(t),\\
        f'(-t)+g'(t) = 0,
    \end{cases} \Longrightarrow f(\xi) = \frac{1}{2}\sin(-\xi), \quad g(\eta) = \frac{1}{2}\sin(\eta),
\end{align}
$$
so, $u(t,x) = \frac12 \left( \sin(x+t) + \sin(-x+t) \right)$.




---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

# Theorem (Cauchy-Kovalesvskaya Theorem)
Consider a Cauchy problem for a linear PDE, let $x^0$ be a point of the initial surface $S$, which is assumed to be analytic (very regular). Suppose that $S$ is not a characteristic surface at the point $x^0$. Assume that all the coefficients of the linear PDE, the right-hand side $g$, and all the initial data $f_0 , f_1 ,\dots, f_{k−1}$ are analytic functions on a neighbourhood of the point $x^0$. Then, the Cauchy problem has a solution $u$, defined in the neighbourhood of $x^0$. Moreover, the solution u is analytic in a neighbourhood of $x^0$ and it is unique in the class of analytic functions.

* Assumptions: Regularity
* Outcome: Existence
* Outcome: Uniqueness
* Outcome: Regularity of the solution

$\,$
* Is this enough? No, the solution might still mis-behave


---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

# Well-posedness


## Definition
A PDE problem is well-posed if:
1. The PDE has a solution
2. The solution is unique
3. The solution depends continuously on the PDE coefficients and on the problem data (IC/BC)

If the PDE problem is not well-posed, we say it is ill-posed.







---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Exercise
Show that the solution of the Cauchy problem for the wave equation 
$$
\begin{cases}
    \partial_{tt} u - \partial_{xx} u =0,\\
    u(t,0) = f(t),\\
    u_x(t,0) = g(t)
\end{cases}
$$
for some known BCs $f$ and $g$ is given by the d'Alembert's formula
$$
u(t,x) = \frac12 (f(t-x)+f(t+x)) + \frac12 \int_{t-x}^{t+x}g(s) \textrm{d}s.
$$
Show that the Cauchy problem is well-posed (skipping the uniqueness). *


---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Exercise *
1. Find the solution of the Laplace equation on $\Omega=[0,2\pi]$ for various $k$
$$
\begin{cases}
    \partial_{tt} u + \partial_{xx} u =0,\\
    u(0,x) = 0,\\
    u_t(0,x) = \frac{\sin(kx)}{k},\\
    u(0,t)=u(2\pi,t).
\end{cases}
$$
Steps:
* $u_k = \frac{a_0(t)}{2} + \sum_{n=1}^{\infty} [a_n(t) \cos (nx) + b_n(t)\sin(nx)]$
* Substitute in the equation and find the general solution using the method of separation of variables
* $\partial_{tt} a_n(t)=n^2 a_n(t)$ for all $n$ with $a_n(0)=0, \partial_t a_n(0)=0$
* $\partial_{tt} b_n(t)=n^2 b_n(t)$ for all $n$ with $b_n(0)=0, \partial_t b_n(0)=0$ for $n\neq k$, $\partial_t b_k(0)=1/k$.
* $u_k(t,x)= \frac{1}{k^2}\sin(kx) \sinh(kt)$ 

2. Even if $\sup_x |u_k(0,x)| + |\partial_t u_k(0,x)|$ is small, we can find large enough $k$ so that for any time $t_0>0$ $\sup_x |u_k(t_0,x)| + |\partial_t u_k(t_0,x)|$ is large.

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

### Theorem *
Let $u_k(t,x) =  \frac{1}{k^2}\sin(kx) \sinh(kt)$. For any positive $\varepsilon, M, t_0$ there exists an integer $K$ such that for any $k>K$ the initial data satisfies $\sup_x |u_k(0,x)| + |\partial_t u_k(0,x)|<\varepsilon$ but the solution at the time $t_0$ satisfies $\sup_x |u_k(t_0,x)| + |\partial_t u_k(t_0,x)|>M$.
**Proof:** Choosing an integer $K_1$ satisfying $K_1 > \frac{1}{\epsilon}$ we will have the initial condition inequality for any $k \geq K_1$. In order to obtain a lower estimate of the second form at time $t_0$ let us first observe that
$$\sup_{x \in [0, 2\pi]} (|u_k (x, t)| + |\partial_t u_k (x, t)|) = \frac{1}{k^2}  \sinh(kt) + \frac{1}{k} \cosh(kt) > \frac{1}{k^2} e^{kt}$$
where we have used an obvious inequality $\frac{1}{k} > \frac{1}{k^2} \text{ for } k > 1.$
The function $y = \frac{e^x}{x^2}$ is monotone increasing for $x > 2$ and $\lim_{x \to +\infty} \frac{e^x}{x^2} = +\infty.$
Hence for any $t_0 > 0$ there exists $x_0$ such that $\frac{e^x}{x^2} > \frac{M}{t_0^2} \text{ for } x > x_0.$
Let $K_2$ be a positive integer satisfying $K_2 > \frac{x_0}{t_0}.$
Then for any $k > K_2$ 
$$\frac{e^{kt_0}}{k^2} = t_0^2 \frac{e^{kt_0}}{k^2t_0^2} > t_0^2\frac{e^{x_0}}{x_0^2} > M.$$
Choosing $K = \max(K_1, K_2)$ we complete the proof of the Theorem.

---
<style scoped>section{font-size:23px;padding-top:30px;align-content: start;}</style>

## Take home message
Not all boundary conditions are suitable for having a well-posed problem.